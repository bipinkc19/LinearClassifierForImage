{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.plugins.beholder import Beholder\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pickle.load(open(\"X_train.pickle\", \"rb\"))\n",
    "# y_train = pickle.load(open(\"y_train.pickle\", \"rb\"))\n",
    "# X_test = pickle.load(open(\"X_test.pickle\", \"rb\"))\n",
    "# y_test = pickle.load(open(\"y_test.pickle\", \"rb\"))\n",
    "\n",
    "\n",
    "# X_train = X_train.astype('float32')\n",
    "# y_train = y_train.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "# y_test = y_test.astype('float32')\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot = {0:[1, 0],\n",
    "#            1:[0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = {0: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "           1: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "           2: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "           3: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "           4: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "           5: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "           6: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "           7: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "           8: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "           9: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels_test = []\n",
    "y_labels_train = []\n",
    "for y in y_test:\n",
    "    y_labels_test.append(one_hot[y])\n",
    "for y in y_train:\n",
    "    y_labels_train.append(one_hot[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_test[5])\n",
    "\n",
    "plt.show()\n",
    "print(y_labels_test[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = 'seventh'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 500\n",
    "LR = 0.5e-5\n",
    "IMG_FLATTEN = 28 * 28\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(num, data, labels):\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def network(x):\n",
    "    with tf.name_scope(\"Reshape\"):    \n",
    "        x_image = tf.reshape(x, [-1, IMG_FLATTEN])\n",
    "    with tf.name_scope(\"Magic\"):\n",
    "        Y = tf.matmul(x_image, W) + B\n",
    "    return Y\n",
    "\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "    \n",
    "with tf.name_scope(\"inputs\"):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 28, 28], name=\"x\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "    \n",
    "with tf.name_scope(\"weight\"):\n",
    "    W = tf.Variable(tf.truncated_normal([IMG_FLATTEN, n_classes], stddev=0.5))\n",
    "    tf.summary.histogram(\"weight\", W)\n",
    "with tf.name_scope(\"bias\"):\n",
    "    B = tf.Variable(tf.truncated_normal([1, n_classes], stddev=0.5))\n",
    "    tf.summary.histogram(\"bias\", W)\n",
    "\n",
    "logits = network(x)\n",
    "\n",
    "with tf.name_scope(\"xent\"):\n",
    "    xent = tf.reduce_mean(\n",
    "                    tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                    labels=y, logits=logits), name=\"xent\")\n",
    "    tf.summary.scalar(\"xent\", xent)\n",
    "    \n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(LR, name='Adam').minimize(xent)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "with tf.name_scope(\"accuracy_val\"):\n",
    "    correct_prediction_val = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy_val = tf.reduce_mean(tf.cast(correct_prediction_val, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy_val\", accuracy_val)\n",
    "\n",
    "summ = tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "        \n",
    "    beholder = Beholder(LOGDIR)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(LOGDIR)\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    for i in range(EPOCHS):\n",
    "        \n",
    "        [train_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: X_train[0:700], y: y_labels_train[0:700]})\n",
    "        [test_accuracy, s] = sess.run([accuracy_val, summ], feed_dict={x: X_test[0:700], y: y_labels_test[0:700]})\n",
    "        writer.add_summary(s, i)\n",
    "\n",
    "            \n",
    "        for j in range(math.ceil(len(X_train) / BATCH_SIZE)):\n",
    "            batch_x, batch_y = next_batch(num = BATCH_SIZE, data = X_train, labels = y_labels_train)\n",
    "            sess.run(train_step, feed_dict={x: batch_x, y: batch_y})\n",
    "        beholder.update(session=sess)\n",
    "\n",
    "    export_path =  './savedmodel7'\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "    tensor_info_x = tf.saved_model.utils.build_tensor_info(x)\n",
    "    tensor_info_y = tf.saved_model.utils.build_tensor_info(logits)\n",
    "\n",
    "    prediction_signature = (\n",
    "      tf.saved_model.signature_def_utils.build_signature_def(\n",
    "          inputs={'x_input': tensor_info_x},\n",
    "          outputs={'y_output': tensor_info_y},\n",
    "          method_name=tf.saved_model.signature_constants.PREDICT_METHOD_NAME))\n",
    "\n",
    "    builder.add_meta_graph_and_variables(\n",
    "      sess, [tf.saved_model.tag_constants.SERVING],\n",
    "      signature_def_map={\n",
    "          tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "              prediction_signature \n",
    "      },\n",
    "      )\n",
    "    builder.save()\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# X_test = pickle.load(open(\"X_test.pickle\", \"rb\"))\n",
    "# y_test = pickle.load(open(\"y_test.pickle\", \"rb\"))\n",
    "\n",
    "# X_test = X_test.astype('float32')\n",
    "# y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "with tf.Session() as sess:\n",
    "    signature_key = tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "    input_key = 'x_input'\n",
    "    output_key = 'y_output'\n",
    "\n",
    "    export_path =  './savedmodel7'\n",
    "    meta_graph_def = tf.saved_model.loader.load(\n",
    "               sess,\n",
    "              [tf.saved_model.tag_constants.SERVING],\n",
    "              export_path)\n",
    "    signature = meta_graph_def.signature_def\n",
    "\n",
    "    x_tensor_name = signature[signature_key].inputs[input_key].name\n",
    "    y_tensor_name = signature[signature_key].outputs[output_key].name\n",
    "\n",
    "    x = sess.graph.get_tensor_by_name(x_tensor_name)\n",
    "    y = sess.graph.get_tensor_by_name(y_tensor_name)\n",
    "\n",
    "    y_out = sess.run(y, {x: X_test})\n",
    "    vars = tf.trainable_variables()\n",
    "    print(vars) #some infos about variables...\n",
    "    vars_vals = sess.run(vars)\n",
    "    vizs = []\n",
    "    for var, val in zip(vars, vars_vals):\n",
    "#         print(\"var: {}, value: {}\".format(var.name, val))\n",
    "        vizs.append(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights for all the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for j in range(10):\n",
    "    z = []\n",
    "    for i in range(784):\n",
    "        z.append(vizs[0][i][j])\n",
    "    z = np.array(z)\n",
    "    bb = np.reshape(z, (28, 28))\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.imshow(bb, cmap = \"gray\")\n",
    "    print(j)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicted_values = []\n",
    "for i in range(len(y_out)):\n",
    "    index_max = np.argmax(y_out[i])\n",
    "    predicted_values.append(index_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def imshow(img):\n",
    " # unnormalize\n",
    "    #npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(img[0], (1, 2, 0)))\n",
    "    plt.show()\n",
    "plt.imshow(X_test[1], cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics(actual, pred, msg):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(actual, pred)\n",
    "    import seaborn as sns     \n",
    "\n",
    "    plt.figure()\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot = True, fmt = 'g')\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels')\n",
    "    ax.set_ylabel('True labels') \n",
    "    ax.set_title('Confusion Matrix')\n",
    "    ax.xaxis.set_ticklabels(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']) \n",
    "    ax.yaxis.set_ticklabels(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'])   \n",
    "    plt.show()       \n",
    "    sensitivity = cm[1][1]/(cm[1][0] + cm[1][1])\n",
    "    specifity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    accuracy = (cm[0][0] + cm[1][1]) / np.sum(cm)\n",
    "    \n",
    "#     print(msg, '\\n')\n",
    "#     print('accuracy:    ', round(accuracy,2), \n",
    "#       '\\nsensitivity: ', round(sensitivity,2), \n",
    "#       '\\nspecifity:   ', round(specifity,2))\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(actual, pred))\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_metrics((y_test).astype(int), predicted_values, msg = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
